{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc27bf47-b6dd-4542-b801-60793bb3c9f1",
   "metadata": {},
   "source": [
    "# Feature Engineering – Feature Scaling\n",
    " \n",
    "**Feature Scaling** is a preprocessing technique used to adjust the range of numerical features in a dataset, so they fall within a specific scale, often to make them comparable and improve model performance.\n",
    "\n",
    "## Why is Feature Scaling Important?\n",
    "**1. Ensures Fairness**                         \n",
    "Suppose you have two features:                   \n",
    "* Age: Ranges from 18 to 100.                  \n",
    "* Income: Ranges from 10,000 to 1,00,000.                           \n",
    "If you don’t scale the features, the Income feature (larger range) will dominate models like Linear Regression or Logistic Regression because its numerical values are much higher than those of the Age feature. This will make the model prioritize Income over Age, which might not be ideal.\n",
    "Example (Without Scaling):                                         \n",
    "* The model could interpret a change of +1 in Age (e.g., 25 → 26) as much less important than a +1 in Income (e.g., 50,000 → 50,001).\n",
    "\n",
    "  \n",
    "**2. Model Convergence**                          \n",
    "* Gradient Descent-based models (e.g., Logistic Regression, Neural Networks) rely on minimizing a loss function.                       \n",
    "* If one feature has values between 0 and 1 and another between 1,000 and 10,000, the gradient updates will vary significantly, slowing convergence.\n",
    "* Example:                                    \n",
    "Imagine climbing a hill where one side is smooth, but the other side is bumpy and steep. You’ll struggle to move smoothly toward the peak. Similarly, the optimization algorithm struggles when feature scales are inconsistent.                                      \n",
    "\n",
    "**3. Improves Accuracy for Distance-Based Algorithms**                          \n",
    "* Distance-based algorithms like KNN and SVM rely on calculating the distance between points.                      \n",
    "* Example (Without Scaling):                                            \n",
    "If you calculate the Euclidean distance between two data points:              \n",
    "The distance formula is given by:                     \n",
    "\n",
    "$$\n",
    "\\text{Distance} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\(x\\) represents **Income**   \n",
    "- \\(y\\) represents **Age**\n",
    " \n",
    "If Income is on a much larger scale, the distance will primarily be influenced by differences in Income, ignoring Age.              \n",
    "\n",
    "**4. Consistency**                            \n",
    "* Features on vastly different scales can confuse the model during training, leading to inconsistent results.                \n",
    "* Example (With Scaling):                            \n",
    "After scaling, both Age and Income will have a mean of 0 and a standard deviation of 1 (if using StandardScaler). This ensures the model treats all features equally, leading to more reliable predictions.                \n",
    "\n",
    "## When is Feature Scaling Needed?\n",
    "* Required for algorithms that rely on distances or gradients (e.g., KNN, SVM, Logistic Regression, Neural Networks).           \n",
    "* Not Required for tree-based algorithms like Decision Trees, Random Forests, and XGBoost (they are scale-invariant).         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf157152-abfb-41f4-aad3-cfc6338b0239",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a540544-f637-49bf-bf3b-1c8b661462ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for Scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "#Libraries for visualizations \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc942f9-efa9-4d4d-9d2f-2caede8998af",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c976972-55d5-4386-a895-fcf5d532cb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Country_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Devloping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Developed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>Devloping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Developed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Devloping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Salary Country_Type\n",
       "0           1      30    Devloping\n",
       "1           3      35    Developed\n",
       "2           4      43    Devloping\n",
       "3           5      36    Developed\n",
       "4           6      27    Devloping"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\BINPAT\\\\Documents\\\\Python Self\\\\Feature Engineering\\\\Datasets\\\\Scaling.xlsx\")  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7737d1-85d9-4f8b-b296-a666d82c881b",
   "metadata": {},
   "source": [
    "## 3. Extracting basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd6adc4-287d-4ce6-b027-4560ea581674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Experience    15 non-null     int64 \n",
      " 1   Salary        15 non-null     int64 \n",
      " 2   Country_Type  15 non-null     object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 492.0+ bytes\n",
      "\n",
      "Column Names:\n",
      "Index(['Experience', 'Salary', 'Country_Type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "df.info()\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de361186-00c8-4697-a39c-eda4bf0a824b",
   "metadata": {},
   "source": [
    "## 1. Standardization (Z-Score Normalization)\n",
    "Standardization is the process of rescaling the features so that they have a mean of 0 and a standard deviation of 1. This technique is commonly used when the data follows a Gaussian (normal) distribution.\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "Where:  \n",
    "- X is the feature value.  \n",
    "- meu is the mean of the feature.  \n",
    "- sigma is the standard deviation of the feature.\n",
    "\n",
    "**When to Use:**  \n",
    "- When the data is normally distributed (or close to it).  \n",
    "- For algorithms like Logistic Regression, KNN, SVM, and Neural Networks that are sensitive to the scale of the data.\n",
    "\n",
    "**Pros:**  \n",
    "- Preserves the distribution of the data.  \n",
    "- Useful for many machine learning algorithms.  \n",
    "- Works well when features have different units.\n",
    "\n",
    "**Cons:**  \n",
    "- Sensitive to outliers; can distort the data if outliers are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c59dbd2-377f-4b0e-9c5d-f884f9feaef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization (Z-Score Normalization):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Country_Type</th>\n",
       "      <th>Experience_SS</th>\n",
       "      <th>Salary_SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>-1.689306</td>\n",
       "      <td>0.596869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Developed</td>\n",
       "      <td>-0.355643</td>\n",
       "      <td>1.044520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>0.311188</td>\n",
       "      <td>1.760763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Developed</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>1.134051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>1.644851</td>\n",
       "      <td>0.328278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Salary Country_Type  Experience_SS  Salary_SS\n",
       "0           1      30    Devloping      -1.689306   0.596869\n",
       "1           3      35    Developed      -0.355643   1.044520\n",
       "2           4      43    Devloping       0.311188   1.760763\n",
       "3           5      36    Developed       0.978019   1.134051\n",
       "4           6      27    Devloping       1.644851   0.328278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardizing the 'Experience' and 'Salary' columns\n",
    "df[['Experience_SS', 'Salary_SS']] = scaler.fit_transform(df[['Experience', 'Salary']])\n",
    "\n",
    "print(\"Standardization (Z-Score Normalization):\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4dfdf-0c93-42c6-857b-5383ca588aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5061ee56-5e8d-4a21-808a-7b0f96fc6688",
   "metadata": {},
   "source": [
    "## 2. Min-Max Scaling (Normalization)\n",
    "Min-Max Scaling scales the data to a fixed range, typically [0, 1], based on the minimum and maximum values of each feature.\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "X' = \\frac{X - \\text{min}(X)}{\\text{max}(X) - \\text{min}(X)}\n",
    "$$\n",
    "Where:  \n",
    "- X is the feature value.  \n",
    "- min(X) is the minimum value of the feature.  \n",
    "- max(X) is the maximum value of the feature.\n",
    "\n",
    "**When to Use:**  \n",
    "- When you want to scale the features to a specific range.  \n",
    "- For algorithms like KNN, Neural Networks, and Gradient Descent where the scale affects the distance metric.\n",
    "\n",
    "**Pros:**  \n",
    "- Simple and easy to interpret.  \n",
    "- Scales the data into a predefined range.\n",
    "\n",
    "**Cons:**  \n",
    "- Sensitive to outliers (outliers can distort the range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae868483-d942-43f9-b11a-d798f828cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min-Max Scaling (Normalization):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Country_Type</th>\n",
       "      <th>Experience_SS</th>\n",
       "      <th>Salary_SS</th>\n",
       "      <th>Experience_MM</th>\n",
       "      <th>Salary_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>-1.689306</td>\n",
       "      <td>0.596869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Developed</td>\n",
       "      <td>-0.355643</td>\n",
       "      <td>1.044520</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>0.311188</td>\n",
       "      <td>1.760763</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Developed</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>1.134051</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>1.644851</td>\n",
       "      <td>0.328278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Salary Country_Type  Experience_SS  Salary_SS  Experience_MM  \\\n",
       "0           1      30    Devloping      -1.689306   0.596869            0.0   \n",
       "1           3      35    Developed      -0.355643   1.044520            0.4   \n",
       "2           4      43    Devloping       0.311188   1.760763            0.6   \n",
       "3           5      36    Developed       0.978019   1.134051            0.8   \n",
       "4           6      27    Devloping       1.644851   0.328278            1.0   \n",
       "\n",
       "   Salary_MM  \n",
       "0   0.628571  \n",
       "1   0.771429  \n",
       "2   1.000000  \n",
       "3   0.800000  \n",
       "4   0.542857  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Applying Min-Max Scaling to 'Experience' and 'Salary' columns\n",
    "df[['Experience_MM', 'Salary_MM']] = min_max_scaler.fit_transform(df[['Experience', 'Salary']])\n",
    "\n",
    "print(\"\\nMin-Max Scaling (Normalization):\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c4d8a-731b-4a07-b514-21814f91581b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82f079-ca29-4b5a-85cc-205609bf32c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e7d879-e398-4da7-b4d6-26650e270f96",
   "metadata": {},
   "source": [
    "## 3. Robust Scaling\n",
    "Robust Scaling uses the median and the interquartile range (IQR) for scaling, which makes it less sensitive to outliers compared to Standardization and Min-Max Scaling.\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "X' = \\frac{X - \\text{Median}(X)}{\\text{IQR}(X)}\n",
    "$$\n",
    "Where:  \n",
    "- Median(X) is the median of the feature.  \n",
    "- IQR(X) is the interquartile range of the feature.\n",
    "\n",
    "**When to Use:**  \n",
    "- When the dataset contains outliers that you do not want to distort the scaling.  \n",
    "- Works well for algorithms that are robust to outliers (e.g., Tree-based algorithms).\n",
    "\n",
    "**Pros:**  \n",
    "- Not sensitive to outliers.  \n",
    "- Works well with skewed data.\n",
    "\n",
    "**Cons:**  \n",
    "- Can be less effective if the data is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5171f15e-922f-42ed-b05a-f6d5774c5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Robust Scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Country_Type</th>\n",
       "      <th>Experience_SS</th>\n",
       "      <th>Salary_SS</th>\n",
       "      <th>Experience_MM</th>\n",
       "      <th>Salary_MM</th>\n",
       "      <th>Experience_RS</th>\n",
       "      <th>Salary_RS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>-1.689306</td>\n",
       "      <td>0.596869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Developed</td>\n",
       "      <td>-0.355643</td>\n",
       "      <td>1.044520</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>0.311188</td>\n",
       "      <td>1.760763</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Developed</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>1.134051</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>1.644851</td>\n",
       "      <td>0.328278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.292683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Salary Country_Type  Experience_SS  Salary_SS  Experience_MM  \\\n",
       "0           1      30    Devloping      -1.689306   0.596869            0.0   \n",
       "1           3      35    Developed      -0.355643   1.044520            0.4   \n",
       "2           4      43    Devloping       0.311188   1.760763            0.6   \n",
       "3           5      36    Developed       0.978019   1.134051            0.8   \n",
       "4           6      27    Devloping       1.644851   0.328278            1.0   \n",
       "\n",
       "   Salary_MM  Experience_RS  Salary_RS  \n",
       "0   0.628571           -1.2   0.439024  \n",
       "1   0.771429           -0.4   0.682927  \n",
       "2   1.000000            0.0   1.073171  \n",
       "3   0.800000            0.4   0.731707  \n",
       "4   0.542857            0.8   0.292683  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Applying Robust Scaling to 'Experience' and 'Salary' columns\n",
    "df[['Experience_RS', 'Salary_RS']] = robust_scaler.fit_transform(df[['Experience', 'Salary']])\n",
    "\n",
    "print(\"\\nRobust Scaling:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc328762-929b-499e-8640-350bdd7bcd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d41328-4a21-4740-acc3-0314e6d897a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39a148ac-d3fe-441c-b450-bde49358a9fe",
   "metadata": {},
   "source": [
    "## 4. Log Transformation\n",
    "Log Transformation applies the logarithmic function to each feature, which compresses large values and helps to normalize data that is positively skewed.\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "X' = \\log(X + 1)\n",
    "$$\n",
    "Where:  \n",
    "- \\(X\\) is the feature value.  \n",
    "- The \"+1\" ensures there are no issues with zero or negative values.\n",
    "\n",
    "**When to Use:**  \n",
    "- When the data is highly skewed (e.g., income, population).  \n",
    "- When you want to reduce the effect of large values in the dataset.\n",
    "\n",
    "**Pros:**  \n",
    "- Reduces skewness and helps with non-linear relationships.  \n",
    "- Can handle data with exponential growth patterns.\n",
    "\n",
    "**Cons:**  \n",
    "- Only works for positive values (log transformation is undefined for zero or negative values).  \n",
    "- Can distort the interpretation of original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8231e8-cd61-4c3a-9ae8-3ef669c57972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log Transformation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Country_Type</th>\n",
       "      <th>Experience_SS</th>\n",
       "      <th>Salary_SS</th>\n",
       "      <th>Experience_MM</th>\n",
       "      <th>Salary_MM</th>\n",
       "      <th>Experience_RS</th>\n",
       "      <th>Salary_RS</th>\n",
       "      <th>Experience_log</th>\n",
       "      <th>Salary_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>-1.689306</td>\n",
       "      <td>0.596869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Developed</td>\n",
       "      <td>-0.355643</td>\n",
       "      <td>1.044520</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.583519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>0.311188</td>\n",
       "      <td>1.760763</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.073171</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.784190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Developed</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>1.134051</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.610918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>1.644851</td>\n",
       "      <td>0.328278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.332205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Salary Country_Type  Experience_SS  Salary_SS  Experience_MM  \\\n",
       "0           1      30    Devloping      -1.689306   0.596869            0.0   \n",
       "1           3      35    Developed      -0.355643   1.044520            0.4   \n",
       "2           4      43    Devloping       0.311188   1.760763            0.6   \n",
       "3           5      36    Developed       0.978019   1.134051            0.8   \n",
       "4           6      27    Devloping       1.644851   0.328278            1.0   \n",
       "\n",
       "   Salary_MM  Experience_RS  Salary_RS  Experience_log  Salary_log  \n",
       "0   0.628571           -1.2   0.439024        0.693147    3.433987  \n",
       "1   0.771429           -0.4   0.682927        1.386294    3.583519  \n",
       "2   1.000000            0.0   1.073171        1.609438    3.784190  \n",
       "3   0.800000            0.4   0.731707        1.791759    3.610918  \n",
       "4   0.542857            0.8   0.292683        1.945910    3.332205  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Log Transformation (ensure data is positive before applying)\n",
    "\n",
    "df['Experience_log'] = np.log1p(df['Experience'])\n",
    "df['Salary_log'] = np.log1p(df['Salary'])\n",
    "\n",
    "print(\"\\nLog Transformation:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a479a3-3066-4241-a234-fea4c497160f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f376e28-6f2b-4ee3-89ca-a4ef572314a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4c6c7c-e2ff-405d-9e02-b0e09f6674ee",
   "metadata": {},
   "source": [
    "## 5. Power Transformation (Box-Cox) \n",
    "Power Transformation is used to stabilize variance and make data more Gaussian. Box-Cox is a family of transformations that includes log, square root, and others, based on a parameter $$\\lambda.$$\n",
    "\n",
    "**Formula (Box-Cox):**\n",
    "$$\n",
    "X' = \\frac{X^\\lambda - 1}{\\lambda} \\quad \\text{for} \\quad \\lambda \\neq 0\n",
    "$$\n",
    "If lambda = 0, the transformation is equivalent to the log transformation.\n",
    "\n",
    "**When to Use:**  \n",
    "- When data is skewed or has non-constant variance.  \n",
    "- Used when we want to transform the data to approximate a normal distribution.\n",
    "\n",
    "**Pros:**  \n",
    "- Stabilizes variance.  \n",
    "- Useful for linear models that assume normality.\n",
    "\n",
    "**Cons:**  \n",
    "- Requires the data to be strictly positive (cannot be used with zero or negative values).\n",
    "- The optimal value of lambda may need to be found using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad713266-96d3-4c28-bd11-7c6cfb3236a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Power Transformation (Box-Cox):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Country_Type</th>\n",
       "      <th>Experience_SS</th>\n",
       "      <th>Salary_SS</th>\n",
       "      <th>Experience_MM</th>\n",
       "      <th>Salary_MM</th>\n",
       "      <th>Experience_RS</th>\n",
       "      <th>Salary_RS</th>\n",
       "      <th>Experience_log</th>\n",
       "      <th>Salary_log</th>\n",
       "      <th>Experience_PT</th>\n",
       "      <th>Salary_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>-1.689306</td>\n",
       "      <td>0.596869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>-1.649095</td>\n",
       "      <td>0.686905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Developed</td>\n",
       "      <td>-0.355643</td>\n",
       "      <td>1.044520</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>-0.381695</td>\n",
       "      <td>1.032429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>0.311188</td>\n",
       "      <td>1.760763</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.073171</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>0.291395</td>\n",
       "      <td>1.523073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>Developed</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>1.134051</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>1.097565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Devloping</td>\n",
       "      <td>1.644851</td>\n",
       "      <td>0.328278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>1.693885</td>\n",
       "      <td>0.461058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Salary Country_Type  Experience_SS  Salary_SS  Experience_MM  \\\n",
       "0           1      30    Devloping      -1.689306   0.596869            0.0   \n",
       "1           3      35    Developed      -0.355643   1.044520            0.4   \n",
       "2           4      43    Devloping       0.311188   1.760763            0.6   \n",
       "3           5      36    Developed       0.978019   1.134051            0.8   \n",
       "4           6      27    Devloping       1.644851   0.328278            1.0   \n",
       "\n",
       "   Salary_MM  Experience_RS  Salary_RS  Experience_log  Salary_log  \\\n",
       "0   0.628571           -1.2   0.439024        0.693147    3.433987   \n",
       "1   0.771429           -0.4   0.682927        1.386294    3.583519   \n",
       "2   1.000000            0.0   1.073171        1.609438    3.784190   \n",
       "3   0.800000            0.4   0.731707        1.791759    3.610918   \n",
       "4   0.542857            0.8   0.292683        1.945910    3.332205   \n",
       "\n",
       "   Experience_PT  Salary_PT  \n",
       "0      -1.649095   0.686905  \n",
       "1      -0.381695   1.032429  \n",
       "2       0.291395   1.523073  \n",
       "3       0.984215   1.097565  \n",
       "4       1.693885   0.461058  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_transformer = PowerTransformer()\n",
    "\n",
    "# Applying Power Transformation to 'Experience' and 'Salary' columns\n",
    "df[['Experience_PT', 'Salary_PT']] = power_transformer.fit_transform(df[['Experience', 'Salary']])\n",
    "\n",
    "print(\"\\nPower Transformation (Box-Cox):\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d216ef-34dc-46b5-89f0-ffae8559b876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "897c2cf8-def2-4e8f-afad-9bc94045fe51",
   "metadata": {},
   "source": [
    "# Now lets check which one is effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40c28ede-6dc9-48f9-bfd1-5036f468530b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Experience', 'Salary', 'Country_Type', 'Experience_SS', 'Salary_SS',\n",
       "       'Experience_MM', 'Salary_MM', 'Experience_RS', 'Salary_RS',\n",
       "       'Experience_log', 'Salary_log', 'Experience_PT', 'Salary_PT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b62196cb-5326-426b-b5fa-98cd643050a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Before Scaling:\n",
      "Experience      2.409524\n",
      "Salary        133.666667\n",
      "dtype: float64\n",
      "\n",
      "Variance After Scaling:\n",
      "Experience_SS     1.071429\n",
      "Salary_SS         1.071429\n",
      "Experience_MM     0.096381\n",
      "Salary_MM         0.109116\n",
      "Experience_RS     0.385524\n",
      "Salary_RS         0.318065\n",
      "Experience_log    0.156705\n",
      "Salary_log        0.270403\n",
      "Experience_PT     1.071429\n",
      "Salary_PT         1.071429\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Variance Calculation\n",
    "# Calculate variance before and after scaling\n",
    "variance_before = df[['Experience', 'Salary']].var()\n",
    "variance_after = df[['Experience_SS', 'Salary_SS', 'Experience_MM', 'Salary_MM', \n",
    "                     'Experience_RS', 'Salary_RS', 'Experience_log', 'Salary_log', \n",
    "                     'Experience_PT', 'Salary_PT']].var()\n",
    "\n",
    "# Display variances\n",
    "print(\"Variance Before Scaling:\") \n",
    "print(variance_before)\n",
    "print(\"\\nVariance After Scaling:\")\n",
    "print(variance_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30a224-25ea-4087-84aa-f1a35a4e6173",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Before scaling, the variance of the `Experience` and `Salary` columns was significantly higher, especially for `Salary` (133.67), indicating a wide range of values. After applying various scaling techniques, we observe that:\n",
    "\n",
    "- **Standard Scaling (Experience_SS, Salary_SS)** reduced the variance to a consistent 1.071429 for both features, ensuring that they are on a comparable scale.\n",
    "- **Min-Max Scaling (Experience_MM, Salary_MM)** resulted in very low variances (close to 0), as values were compressed into a small range.\n",
    "- **Robust Scaling (Experience_RS, Salary_RS)** and **Log Transformation (Experience_log, Salary_log)** also decreased variance, with robust scaling being more resistant to outliers.\n",
    "- **Power Transformation (Experience_PT, Salary_PT)** maintained a variance of 1.071429, similar to Standard Scaling, but with potentially improved handling of non-normal distributions.\n",
    "\n",
    "In summary, scaling techniques like Standard Scaling and Power Transformation preserve the overall variance structure of the data, while Min-Max Scaling and Robust Scaling reduce it, which can be useful depending on the algorithm and model requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83c784-318f-4548-be3e-18b537bfd130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adcc2937-618c-45cd-9bf6-f6ff35d80cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Daviation Before Scaling:\n",
      "Experience     1.552264\n",
      "Salary        11.561430\n",
      "dtype: float64\n",
      "\n",
      "Standard Daviation Scaling:\n",
      "Experience_SS     1.035098\n",
      "Salary_SS         1.035098\n",
      "Experience_MM     0.310453\n",
      "Salary_MM         0.330327\n",
      "Experience_RS     0.620906\n",
      "Salary_RS         0.563972\n",
      "Experience_log    0.395860\n",
      "Salary_log        0.520003\n",
      "Experience_PT     1.035098\n",
      "Salary_PT         1.035098\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Standard Daviation Calculation\n",
    "# Calculate Standard Daviation before and after scaling\n",
    "std_before = df[['Experience', 'Salary']].std()\n",
    "std_after = df[['Experience_SS', 'Salary_SS', 'Experience_MM', 'Salary_MM', \n",
    "                     'Experience_RS', 'Salary_RS', 'Experience_log', 'Salary_log', \n",
    "                     'Experience_PT', 'Salary_PT']].std()\n",
    "\n",
    "# Display variances\n",
    "print(\"Standard Daviation Before Scaling:\") \n",
    "print(std_before)\n",
    "print(\"\\nStandard Daviation Scaling:\")\n",
    "print(std_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90a184-c356-4dca-a73b-b5882cf8f880",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Before scaling, the standard deviation of `Experience` was 1.552264, and `Salary` had a much higher standard deviation of 11.561430, indicating significant spread in the data. After applying various scaling techniques, we observe:\n",
    "\n",
    "- **Standard Scaling (Experience_SS, Salary_SS)** reduced the standard deviation for both features to 1.035098, ensuring that both are on the same scale, centered around 0 with unit variance.\n",
    "- **Min-Max Scaling (Experience_MM, Salary_MM)** further reduced the standard deviation, bringing it down to 0.310453 for `Experience` and 0.330327 for `Salary`, which shows that the values are compressed into a smaller range.\n",
    "- **Robust Scaling (Experience_RS, Salary_RS)** also decreased the standard deviation, with values of 0.620906 for `Experience` and 0.563972 for `Salary`, indicating less sensitivity to outliers compared to other scalers.\n",
    "- **Log Transformation (Experience_log, Salary_log)** reduced the standard deviation, especially for `Salary`, with values of 0.395860 for `Experience` and 0.520003 for `Salary`, helping to compress large values and reduce skewness.\n",
    "- **Power Transformation (Experience_PT, Salary_PT)** provided similar standard deviations (1.035098) as Standard Scaling, maintaining consistency in the data distribution.\n",
    "\n",
    "In conclusion, scaling methods like Standard Scaling and Power Transformation ensure that features have a similar spread. Min-Max Scaling compresses the data into a small range, while Robust Scaling is more robust against outliers. Log and Power Transformations also help reduce skewness, improving model performance for algorithms sensitive to data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82378040-8b74-47a3-86ac-986b42c4e508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6135ddd-d7d1-4249-8a9d-bac30581e0df",
   "metadata": {},
   "source": [
    "## For better understanding , we have to train a ML model and check the MSE OR RMSE score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396723f-a1db-4b72-b479-d1de07431b07",
   "metadata": {},
   "source": [
    "## Pros and Cons of Feature Scaling\n",
    "\n",
    "**Pros:**\n",
    "* Ensures faster convergence in optimization.            \n",
    "* Prevents bias towards features with larger values.            \n",
    "* Improves accuracy for distance-based models.               \n",
    "\n",
    "**Cons:**                              \n",
    "* Adds preprocessing complexity.                      \n",
    "* Can distort data if applied incorrectly (e.g., before train-test splitting).                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27db62f-1fb4-4d6e-8d2a-265ea8051d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
